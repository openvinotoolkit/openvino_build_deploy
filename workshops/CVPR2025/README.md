
# Agentic Workflow Setup Guide

## üöÄ Quick Start

### 1. Environment Setup (Recommended Windows laptop with 32GB RAM)

```bash
Install Python 3.12
git lfs install
git clone https://github.com/openvinotoolkit/openvino_build_deploy.git 
cd openvino_build_deploy/workshops/CVPR2025/
python -m venv env
env/scripts/activate

pip install -r requirements.txt
(refer pip_packages_windows.txt)
choco install ffmpeg
```

## ü§ñ Model Preparation

### Export OpenVINO Models

Run the following commands to prepare the required AI models:

#### Phi-4 Multimodal Instruct Model
```bash
optimum-cli export openvino --model microsoft/phi-4-multimodal-instruct phi-4-multimodal-instruct/INT4 --trust-remote-code --task image-text-to-text --weight-format int4 --group-size 64
```

#### Qwen2.5-7B-Instruct Model
```bash
optimum-cli export openvino -m Qwen/Qwen2.5-7B-Instruct Qwen/Qwen2.5-7B-Instruct/INT4 --trust-remote-code --task text-generation-with-past --weight-format int4 --sym --ratio 1.0 --group-size 128
```

#### BGE Large EN v1.5 Embedding Model
```bash
optimum-cli export openvino --model BAAI/bge-large-en-v1.5 bge-large-en-v1.5-dyn-int4/INT4 --task feature-extraction --trust-remote-code --framework pt --library sentence_transformers --weight-format int4 --group-size 128 --sym --ratio 1
```

#### Whisper Model Conversion
```bash
python convert_whisper_model.py
copy whisper_tokenizers\* files to whisper converted model folder together
(These tokenizers/detokenizers are pre-generated by method in https://docs.openvino.ai/2025/openvino-workflow-generative/ov-tokenizers.html)
```

## ‚öôÔ∏è Configuration

### Environment Variables (`src/.env`)

Create and configure your `src/.env` file with the following variables:

```env
# Directory Paths
HOME_DIR=C:\working\CVPR2025\src
OPENVINO_WHISPER_MODEL_DIR=C:\working\models\whisper-small
OPENVINO_WHISPER_MODEL_DEVICE=GPU
# Use regular whisper model instead of OpenVINO whisper for now
#OPENVINO_WHISPER_MODEL_DIR=small

# BridgeTower Models
TEXT_VISION_BRIDGETOWER_MODEL_PATH=C:\working\models\openvino_bridgetower\bridgetower_models\bridgetower_large_itc.xml
TEXT_BRIDGETOWER_MODEL_PATH=C:\working\models\openvino_bridgetower\bridgetower_models\custombridgetower_text_large_itc.xml
VISION_BRIDGETOWER_MODEL_PATH=TBD
BRIDGETOWER_MODEL_DEVICE=GPU.0

# Vector Store Configuration
VECTORSTORE_TBL_NAME=mmrag
LANCEDB_HOST_FILE=./lancedb_vectorstore/.lancedb
VECTORSTORE_INGESTION_MODE=overwrite

# AI Models
VLM_MODEL_PATH=C:\working\models\phi-4-multimodal-instruct\INT4
VLM_MODEL_DEVICE=GPU.0
LLM_MODEL_PATH=C:\working\models\Qwen\Qwen2.5-7B-Instruct\INT4
LLM_MODEL_DEVICE=GPU.0
EMBEDDING_MODEL_PATH=C:\working\models\bge-large-en-v1.5-dyn-int4\INT4

# MCP Server URLs
URL_VIDEO_PROCESSING_MCP_SERVER=http://localhost:3000/sse
URL_SHOPPING_CART_MCP_SERVER=http://localhost:3001/sse

# Documents
DOCUMENT_PATH=C:\working\CVPR2025\data\test_painting_llm_rag.pdf
```

> **Note**: Use regular whisper model instead of OpenVINO whisper for now

## üñ•Ô∏è Running the Application

### 1. Start MCP Servers

Run the following servers in separate terminal windows:

```bash
cd src

# Shopping Cart MCP Server
python main_shopping_cart_server.py

Log as below:
LLM is explicitly disabled. Using MockLLM.
INFO:     Started server process 
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://localhost:3001 (Press CTRL+C to quit)

# Video Search MCP Server  
python main_search_server.py

Log as below:
üîß BridgeTower Model Configuration:
   üì± Device: GPU.0
   üìÑ Text-Vision Model: bridgetower_large_itc.xml
   üìÑ Text Model: custombridgetower_text_large_itc.xml
   ‚úÖ Text-Vision Model compiled on GPU.0
   ‚úÖ Text Model compiled on GPU.0
INFO:     Started server process 
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://localhost:3000 (Press CTRL+C to quit)
```

### 2. Launch Web Browser Client

```bash
# Set temporary directory for Gradio
set GRADIO_TEMP_DIR='C:\working\CVPR2025\gradio_tmp'

# Start the web interface
python gradio_helper.py
```

## üìù Notes

- Ensure all model paths in the `.env` file point to the correct locations on your system
- GPU devices can be specified as `GPU.0`, `GPU.1`, etc., or use `CPU` for CPU inference
- The Gradio temporary directory should be set to a location with sufficient disk space
