{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v7M6g-P1ZtSi"
   },
   "source": [
    "# Using the OpenVINO™ Execution Provider for YOLOv8 Detection\n",
    "\n",
    "[Source (modified from Microsoft ONNX Runtime OpenVINO EP Examples)](https://github.com/microsoft/onnxruntime-inference-examples/tree/main/python/OpenVINO_EP/yolov8_object_detection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "id": "5BqlWQzFbhf4"
   },
   "outputs": [],
   "source": [
    "#Defining a sample image for inference\n",
    "image_url = \"https://ultralytics.com/images/bus.jpg\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellView": "form",
    "id": "5BqlWQzFbhf4"
   },
   "outputs": [],
   "source": [
    "#Ensure the path to OpenVINO DLLs are in your system PATH\n",
    "import onnxruntime.tools.add_openvino_win_libs as utils\n",
    "utils.add_openvino_libs_to_path()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fYwIEFWpkFqz"
   },
   "source": [
    "## Importing Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "XmHT7vWLkKFy"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import shutil\n",
    "import cv2\n",
    "import numpy as np\n",
    "import onnxruntime as rt\n",
    "import torch\n",
    "from statistics import mean\n",
    "from datetime import datetime\n",
    "from ultralytics import YOLO\n",
    "from ultralytics.data.augment import LetterBox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "W5B11Gp5aZKz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://ultralytics.com/images/bus.jpg\n",
      "Image sucessfully downloaded:  C:\\Users\\raymond\\demo_test\\openvino_build_deploy\\demos\\onnxruntime_yolov8_demo\n"
     ]
    }
   ],
   "source": [
    "# Parameters for pre-processing\n",
    "imgsz = (640,640) # default value for this usecase.\n",
    "stride = 32 # default value for this usecase( differs based on the model selected\n",
    "\n",
    "print(image_url)\n",
    "def preprocess(image_url):\n",
    "    ## Set up the image URL\n",
    "    path = os.getcwd()\n",
    "    image_path=os.path.join(path, image_url.split(\"/\")[-1])\n",
    "    # Open the url image, set stream to True, this will return the stream content.\n",
    "    r = requests.get(image_url, stream = True)\n",
    "    # Check if the image was retrieved successfully\n",
    "    if r.status_code == 200:\n",
    "        # Set decode_content value to True, otherwise the downloaded image file's size will be zero.\n",
    "        r.raw.decode_content = True\n",
    "        # Open a local file with wb ( write binary ) permission.\n",
    "        with open(image_path,'wb') as f:\n",
    "            shutil.copyfileobj(r.raw, f)\n",
    "        print('Image sucessfully downloaded: ',path)\n",
    "    else:\n",
    "        print('Image couldn\\'t be retreived')\n",
    "        return\n",
    "    image_abs_path = os.path.abspath(image_path)\n",
    "    if os.path.isfile(image_abs_path) and image_abs_path.split('.')[-1].lower() in ['jpg', 'jpeg', 'png']:\n",
    "        # Load Image\n",
    "        img0 = cv2.imread(image_abs_path)\n",
    "        # Padded resize\n",
    "        #Letterbox: Resize image and padding for detection, instance segmentation, pose\n",
    "        img = LetterBox(imgsz, stride=stride)(image=img0.copy())\n",
    "        # Convert\n",
    "        img =  img.transpose((2, 0, 1))[::-1]  # BGR to RGB, to 3x416x416\n",
    "        img = np.ascontiguousarray(img)\n",
    "        img = img.astype(np.float32)  # uint8 to fp16/32\n",
    "        img /= 255.0  # 0 - 255 to 0.0 - 1.0\n",
    "        if img.ndim == 3:\n",
    "            img = np.expand_dims(img, axis=0)\n",
    "        return img0, img\n",
    "    else:\n",
    "        print(\"Invalid image format.\")\n",
    "        return\n",
    "\n",
    "org_input, model_input = preprocess(image_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1LOTNlHfhjQT"
   },
   "source": [
    "## Downloading a YOLOv8 Model and Exporting it to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0vAlvihChxnv",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8m.pt to 'yolov8m.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 49.7M/49.7M [00:12<00:00, 4.27MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.81  Python-3.10.11 torch-2.5.0+cpu CPU (Intel Core(TM) Ultra 9 288V)\n",
      "YOLOv8m summary (fused): 218 layers, 25,886,080 parameters, 0 gradients, 78.9 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'yolov8m.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 84, 8400) (49.7 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.16.1 opset 19...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  1.5s, saved as 'yolov8m.onnx' (99.0 MB)\n",
      "\n",
      "Export complete (3.8s)\n",
      "Results saved to \u001b[1mC:\\Users\\raymond\\demo_test\\openvino_build_deploy\\demos\\onnxruntime_yolov8_demo\u001b[0m\n",
      "Predict:         yolo predict task=detect model=yolov8m.onnx imgsz=640  \n",
      "Validate:        yolo val task=detect model=yolov8m.onnx imgsz=640 data=coco.yaml  \n",
      "Visualize:       https://netron.app\n",
      "WARNING  Unable to automatically guess model task, assuming 'task=detect'. Explicitly define task for your model, i.e. 'task=detect', 'segment', 'classify','pose' or 'obb'.\n",
      "Loading yolov8m.onnx for ONNX Runtime inference...\n",
      "\n",
      "Found https://ultralytics.com/images/bus.jpg locally at bus.jpg\n",
      "image 1/1 C:\\Users\\raymond\\demo_test\\openvino_build_deploy\\demos\\onnxruntime_yolov8_demo\\bus.jpg: 640x640 4 persons, 1 bus, 282.2ms\n",
      "Speed: 3.0ms preprocess, 282.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load the YOLOv8 model\n",
    "model = YOLO(\"yolov8m.pt\")\n",
    "\n",
    "# Export the model to ONNX format\n",
    "model.export(format=\"onnx\")  # creates 'yolov8n.onnx'\n",
    "\n",
    "# Load the exported ONNX model\n",
    "onnx_model = YOLO(\"yolov8m.onnx\")\n",
    "\n",
    "# Run inference\n",
    "results = onnx_model(\"https://ultralytics.com/images/bus.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "btKE6yeDgj4T"
   },
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_type = \"NPU\" #CPU, GPU, NPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "WrPPbh0Qgnt-"
   },
   "outputs": [],
   "source": [
    "original_model_path = \"yolov8m.onnx\"\n",
    "\n",
    "def initialize(quantize=False, device='OVEP'):\n",
    "    \"Initialize the model also getting model output and input names\"\n",
    "    initialized = True\n",
    "    model_dir = os.getcwd()\n",
    "    ov_model = None; mlas_model = None\n",
    "    so = rt.SessionOptions()\n",
    "    if device == 'OVEP':\n",
    "        if quantize == True:\n",
    "            print(\"Inferencing through OVEP\")\n",
    "            ov_model = rt.InferenceSession(quantized_model_path, so,\n",
    "                                       providers=['OpenVINOExecutionProvider'],\n",
    "                                       provider_options=[{'device_type' : device_type}])\n",
    "        else:\n",
    "            ov_model = rt.InferenceSession(original_model_path, so,\n",
    "                                       providers=['OpenVINOExecutionProvider'],\n",
    "                                        provider_options=[{'device_type' : device_type}])\n",
    "    elif device == 'CPUEP':\n",
    "        if quantize == True:\n",
    "            mlas_model = rt.InferenceSession(quantized_model_path, so, providers=['CPUExecutionProvider'])\n",
    "        else:\n",
    "            mlas_model = rt.InferenceSession(original_model_path, so, providers=['CPUExecutionProvider'])\n",
    "\n",
    "    if device == 'OVEP':\n",
    "      input_names = ov_model.get_inputs()[0].name\n",
    "      outputs = ov_model.get_outputs()\n",
    "    else:\n",
    "      input_names = mlas_model.get_inputs()[0].name\n",
    "      outputs = mlas_model.get_outputs()\n",
    "    output_names = list(map(lambda output:output.name, outputs))\n",
    "    return input_names, output_names, mlas_model, ov_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IqI1dSmboO1r"
   },
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'OVEP' # OVEP, CPUEP\n",
    "input_names, output_names, mlas_model, ov_model = initialize(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "cellView": "form",
    "id": "h1tYkwGQnKtY"
   },
   "outputs": [],
   "source": [
    "#Select number of iterations for inference\n",
    "no_of_iterations = 100\n",
    "warmup_iterations = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "bVFDmjaQoQhP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing ONNX Runtime Inference with OpenVINO EP.\n",
      "Average inference time is for 97 iterations is 0.0124385625 sec\n"
     ]
    }
   ],
   "source": [
    "inf_lst = []\n",
    "def inference(input_names, output_names, device, mlas_model, ovep_model, model_input):\n",
    "    if device == 'CPUEP':\n",
    "        print(\"Performing ONNX Runtime Inference with default CPU EP.\")\n",
    "        for i in range(no_of_iterations):\n",
    "          start_time = datetime.now()\n",
    "          prediction = mlas_model.run(output_names, {input_names: model_input})\n",
    "          end_time = datetime.now()\n",
    "          # print((end_time - start_time).total_seconds())\n",
    "          if i > warmup_iterations:\n",
    "            inf_lst.append((end_time - start_time).total_seconds())\n",
    "    elif device == 'OVEP':\n",
    "        print(\"Performing ONNX Runtime Inference with OpenVINO EP.\")\n",
    "        for i in range(no_of_iterations):\n",
    "          start_time = datetime.now()\n",
    "          prediction = ovep_model.run(output_names, {input_names: model_input})\n",
    "          end_time = datetime.now()\n",
    "          # print((end_time - start_time).total_seconds())\n",
    "          if i > warmup_iterations:\n",
    "            inf_lst.append((end_time - start_time).total_seconds())\n",
    "    else:\n",
    "        print(\"Invalid Device Option. Supported device options are 'cpu', 'CPU_FP32'.\")\n",
    "        return None\n",
    "    return prediction, (end_time - start_time).total_seconds()\n",
    "\n",
    "inference_output = inference(input_names, output_names, device, mlas_model, ov_model, model_input)\n",
    "average_inference_time = np.average(inf_lst)\n",
    "print(f'Average inference time is for {no_of_iterations - warmup_iterations} iterations is {average_inference_time} sec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T1F3WqTCxA3v"
   },
   "source": [
    "## Final Inference on Image and Webcam Input using OpenVINO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.81  Python-3.10.11 torch-2.5.0+cpu CPU (Intel Core(TM) Ultra 9 288V)\n",
      "YOLOv8m summary (fused): 218 layers, 25,886,080 parameters, 0 gradients, 78.9 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'yolov8m.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 84, 8400) (49.7 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mOpenVINO:\u001b[0m starting export with openvino 2024.3.0-16041-1e3b88e4e3f-releases/2024/3...\n",
      "\u001b[34m\u001b[1mOpenVINO:\u001b[0m export success  3.0s, saved as 'yolov8m_openvino_model\\' (99.1 MB)\n",
      "\n",
      "Export complete (5.1s)\n",
      "Results saved to \u001b[1mC:\\Users\\raymond\\demo_test\\openvino_build_deploy\\demos\\onnxruntime_yolov8_demo\u001b[0m\n",
      "Predict:         yolo predict task=detect model=yolov8m_openvino_model imgsz=640  \n",
      "Validate:        yolo val task=detect model=yolov8m_openvino_model imgsz=640 data=coco.yaml  \n",
      "Visualize:       https://netron.app\n",
      "WARNING  Unable to automatically guess model task, assuming 'task=detect'. Explicitly define task for your model, i.e. 'task=detect', 'segment', 'classify','pose' or 'obb'.\n",
      "Loading yolov8m_openvino_model for OpenVINO inference...\n",
      "Using OpenVINO LATENCY mode for batch=1 inference...\n",
      "\n",
      "image 1/1 C:\\Users\\raymond\\demo_test\\openvino_build_deploy\\demos\\onnxruntime_yolov8_demo\\bus.jpg: 640x640 4 persons, 1 bus, 666.6ms\n",
      "Speed: 9.0ms preprocess, 666.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'bus_predictions.jpg'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Inference on image\n",
    "from ultralytics import YOLO #you can copy and paste these\n",
    "\n",
    "#Download and export to OV format. This will also trigger the OV plugins\n",
    "model = YOLO(\"yolov8m.pt\")\n",
    "model.export(format=\"openvino\")  # creates 'yolov8n_openvino_model/'\n",
    "ov_model = YOLO(\"yolov8m_openvino_model/\") \n",
    "\n",
    "#This will use AUTO Plugin by default, and thus will enable GPU\n",
    "results = ov_model.predict(\"bus.jpg\")\n",
    "results[0].show()  # Show results to screen (in supported environments)\n",
    "results[0].save(filename=f\"bus_predictions.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "m2fxUSilxC-I",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Inference on webcam or live streams\n",
    "import cv2\n",
    "\n",
    "stream = 0 #can set to video path like /path/input.mp4\n",
    "cap = cv2.VideoCapture(stream)\n",
    "assert cap.isOpened(), \"Error reading video file\"\n",
    "w, h, fps = (int(cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS))\n",
    "frame_count = 0\n",
    "while cap.isOpened():\n",
    "    success, im0 = cap.read()\n",
    "    if not success:\n",
    "      print(\"Video frame is empty or video processing has been successfully completed.\")\n",
    "      break\n",
    "    frame_count += 1\n",
    "    results = ov_model.predict(im0, verbose=False)  # Prediction also supported\n",
    "    res_plotted = results[0].plot()\n",
    "    cv2.imshow(\"YOLOv8 OpenVINO Video Stream\", res_plotted)\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release() #Release video sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "Q4cX8riJWuNk"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
