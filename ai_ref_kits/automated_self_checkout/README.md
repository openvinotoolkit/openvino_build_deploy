<div id="top" align="center">
  <h1>Automated Self-Checkout with OpenVINO‚Ñ¢ Toolkit</h1>
  <h4>
    <a href="https://www.intel.com/content/www/us/en/developer/topic-technology/edge-5g/open-potential.html">üè†&nbsp;About&nbsp;the&nbsp;Kits&nbsp;¬∑</a>
    <a href="self-checkout-recipe.ipynb">üìî&nbsp;Jupyter&nbsp;Notebook&nbsp;¬∑</a>
    <a href="https://www.youtube.com/watch?v=VrJRr_thxcs">üì∫&nbsp;Overview&nbsp;Video&nbsp;¬∑</a>
    <a href="https://www.youtube.com/watch?v=rw8cTr-hD-g">üë®‚Äçüíª&nbsp;Code&nbsp;Demo&nbsp;Video&nbsp;¬∑</a>
    <a href="https://www.intel.com/content/www/us/en/developer/articles/training/detect-objects-openvino-automated-self-checkout.html">üìö&nbsp;Step&#8209;by&#8209;step&nbsp;Tutorial</a>
    <a href="envscripts.md">üîß&nbsp;Scripts&nbsp;</a>
  </h4>
</div>

[![Apache License Version 2.0](https://img.shields.io/badge/license-Apache_2.0-green.svg)](https://github.com/openvinotoolkit/openvino_build_deploy/blob/master/LICENSE.txt)

Automated Self-Checkout is designed to help automate checkout for retail businesses by analyzing video streams and detecting and tracking interactions with retail products. It uses OpenVINO‚Ñ¢, a toolkit that enables developers to deploy deep learning models on various hardware platforms.

This kit uses the following technology stack:
- [OpenVINO Toolkit](https://www.intel.com/content/www/us/en/developer/tools/openvino-toolkit/overview.html) ([docs](https://docs.openvino.ai/))
- [Ultralytic YOLOv8](https://github.com/ultralytics/ultralytics)
- [Roboflow Supervision](https://supervision.roboflow.com/latest/)
- [Gradio](https://www.gradio.app/)

Check out our [AI Reference Kits repository](/) for other kits.

![automated-self-checkout](https://github.com/openvinotoolkit/openvino_notebooks/assets/138901786/965a6604-fa15-427e-9d44-c23fa0bbeb6b)

### What's New

[2025-02-26] Gradio-based Demo UI and Scripts.

- It incorporates a new Gradio-based UI that provides interactivity and additional options to view, process, and review the video ([See the Jupyter Notebook](https://github.com/openvinotoolkit/openvino_build_deploy/blob/master/ai_ref_kits/automated_self_checkout/self-checkout-recipe.ipynb)), detections/tracking, and log messages.
- It adds a set of scripts to make it easier to test the demo. For example, you can install, run, or clean the environment and run the demo visually directly (See the ['Scripts'](#scripts-automating-the-installation-running-and-cleaning-demo-tasks) section).

<details open><summary><b>Table of Contents</b></summary>

- [Getting Started](#getting-started)
  - [Scripts automating the Installation, Running, and Cleaning Demo Tasks](#scripts-automating-the-installation-running-and-cleaning-demo-tasks)
  - [Installing Prerequisites](#installing-prerequisites)
  - [Setting Up Your Environment](#setting-up-your-environment)
  - [Running the Application](#running-the-application)
- [Benchmarking the Model with OpenVINO's `Benchmark_App`](#benchmarking-the-model-with-openvinos-benchmark_app)
- [Additional Resources](#additional-resources)

</details>

# Getting Started

Now, let's dive into the steps starting with installing Python. We recommend using Ubuntu to set up and run this project.

## Scripts automating the Installation, Running, and Cleaning Demo Tasks

A set of scripts provides a quick run to install, run, and clean the environment and run the demo visually in a direct way. It targets Ubuntu Linux 22.04+, and an explanation of how to use it is available [here](envscripts.md). On the other hand, you could follow the next steps for a manual and step-by-step installation in case of a different platform.

| Script | Objective |
|:---|:---|
|**setup.sh**|It prepares and installs all required components and a virtual environment to run the JupyterLab server, opening the Automated Self-checkout notebook.|
|**runEnv.sh**|Once installed, it starts the JupyterLab server to continue working in the Tutorial. It starts from the same point where the server was before shut down.|
|**runDemo.sh**|It shows a Gradio-based UI (It executes the tutorial steps in the background) that provides interaction and additional features to explore object detection, tracking algorithm, and UC capacities.|
|**cleanEnv.sh**|It recursively cleans the virtual environment, downloaded model, and the rest of the information under the folder of this reference implementation. It keeps the scripts only in case users wish to reinstall and run the demo again.|

[An explanation of scripts, how to use them, and expected outcomes are available here.](./envscripts.md)

## Star the Repository

Star the [repository](https://github.com/openvinotoolkit/openvino_build_deploy) (optional, but recommended :))

## Installing Prerequisites

This project requires Python 3.9 or higher and a few libraries. If you don't have Python installed on your machine, go to https://www.python.org/downloads/ and download the latest version for your operating system. Follow the prompts to install Python, making sure to check the option to add Python to your PATH environment variable.

Install libraries and tools:

```shell
sudo apt install git git-lfs gcc python3-venv python3-dev
```

_NOTE: If you are using Windows, you will probably need to install [Microsoft Visual C++ Redistributable](https://aka.ms/vs/16/release/vc_redist.x64.exe) also._

## Setting Up Your Environment

### Cloning the Repository

To clone the repository, run the following command:

```shell
git clone https://github.com/openvinotoolkit/openvino_build_deploy.git
```

The above will clone the repository into a directory named "openvino_build_deploy" in the current directory. Then, navigate into the directory using the following command:

```shell
cd openvino_build_deploy/ai_ref_kits/automated_self_checkout
```

Then pull the video sample:

```shell
git lfs -X= -I=data/ pull
```

### Creating a Virtual Environment

To create a virtual environment, open your terminal or command prompt and navigate to the directory where you want to create the environment. Then, run the following command:

```shell
python3 -m venv venv
```
This will create a new virtual environment named "venv" in the current directory.

### Activating the Environment

Activate the virtual environment using the following command:

```shell
source venv/bin/activate   # For Unix-based operating systems such as Linux or macOS
```

_NOTE: If you are using Windows, use `venv\Scripts\activate` command instead._

This will activate the virtual environment and change your shell's prompt to indicate that you are now working within that environment.

### Installing the Packages

To install the required packages, run the following commands:

```shell
python -m pip install --upgrade pip 
pip install -r requirements.txt
```

## Running the Application

You can run [self-checkout-recipe.ipynb](self-checkout-recipe.ipynb) to learn more about the inference process.

<p align="right"><a href="#top">Back to top ‚¨ÜÔ∏è</a></p>

# Benchmarking the Model with OpenVINO's `benchmark_app`

Benchmarking provides insight into your model's real-world performance. Performance may vary based on use and configuration.

### Benchmark Results 

![YOLOv8m Benchmark Results](https://github.com/openvinotoolkit/openvino_notebooks/assets/109281183/2d59819e-61b7-4995-bdf3-a6d1090afdd4)
![](https://github.com/openvinotoolkit/openvino_notebooks/assets/109281183/bed6fc01-f0d4-4f8e-af6a-703182947232)

Benchmarking was performed on an Intel¬Æ Xeon¬Æ Platinum 8480+ (1 socket, 56 cores) running Ubuntu 22.04.2 LTS. The tests utilized the YOLOv8m model with OpenVINO 2023.0. For complete configuration, please check the Appendix section.

### Running the Benchmark

Use the following command to run the benchmark:

```shell
!benchmark_app -m $int8_model_det_path -d $device -hint latency -t 30
```
Replace `int8_model_det_path` with the path to your INT8 model and $device with the specific device you're using (CPU, GPU, etc.). This command performs inference on the model for 30 seconds. Run `benchmark_app --help` for additional command-line options.

Congratulations! You have successfully set up and run the Detection and Tracking for Automated Self-Checkout application with OpenVINO.

### Appendix

Platform Configurations for Performance Benchmarks for YOLOv8m Model

| Type Device | | CPU | | | GPU | |
| :---: | :---: | :---: | :---: | :---: | :---: | :---: |
| System Board | Intel Corporation<br>D50DNP1SBB | AAEON<br>UPN-ADLN01 V1.0<br>220950173 | Intel¬Æ Client Systems<br>NUC12SNKi72 | Intel Corporation<br>M50CYP2SBSTD | Intel¬Æ Client Systems<br>NUC12SNKi72 | Intel¬Æ Client Systems<br>NUC12SNKi72 |
| CPU | Intel(R) Xeon(R) <br>Platinum 8480+ | Intel¬Æ Core‚Ñ¢ <br>i3-N305 @ 3.80 GHz | 12th Gen Intel¬Æ Core‚Ñ¢ <br>i7-12700H @ 2.30 GHz | Intel(R) Xeon(R) <br>Gold 6348 CPU @ 2.60GHz | 12th Gen Intel¬Æ Core‚Ñ¢ <br>i7-12700H @ 2.30 GHz | 12th Gen Intel¬Æ Core‚Ñ¢ <br>i7-12700H @ 2.30 GHz |
| Sockets / Physical cores | 1 /  56 <br>(112 Threads) | 1 / 8 <br>(8 Threads) | 1 /14 <br>(20 Threads) | 2 / 28 <br>(56 Threads) | 1 /14 <br>(20 Threads) | 1 /14 <br>(20 Threads) |
| HyperThreading / Turbo Setting | Enabled / On | Disabled | Enabled / On | Enabled / On | Enabled / On | Enabled / On |
| Memory | 512 GB DDR4 <br>@ 4800 MHz | 16GB DDR5 <br>@4800 MHz | 64 GB DDR4 <br>@ 3200 MHz | 256 GB DDR4 <br>@ 3200 MHz | 64 GB DDR4 <br>@ 3200 MHz | 64 GB DDR4 <br>@ 3200 MHz |
| OS | Ubuntu 22.04.2 LTS | Ubuntu 22.04.2 LTS | Windows 11 <br>Enterprise v22H2 | Ubuntu 22.04.2 LTS | Windows 11 <br>Enterprise v22H2 | Windows 11 <br>Enterprise v22H2 |
| Kernel | 5.15.0-72-generic | 5.15.0-1028-intel-iotg | 22621.1702 | 5.15.0-57-generic | 22621.1702 | 22621.1702 |
| Software | OpenVINO 2023.0 | OpenVINO 2023.0 | OpenVINO 2023.0 | OpenVINO 2023.0 | OpenVINO 2023.0 | OpenVINO 2023.0 |
| BIOS | Intel Corp. <br>SE5C7411.86B.9525<br>.D13.2302071333 | American Megatrends <br>International, <br>LLC. UNADAM10 | Intel Corp. <br>SNADL357.0053<br>.2022.1102.1218 | Intel Corp. <br>SE5C620.86B.01<br>.01.0007.2210270543 | Intel Corp. <br>SNADL357.0053<br>.2022.1102.1218 | Intel Corp. <br>SNADL357.0053<br>.2022.1102.1218 |
| BIOS Release Date | 02/07/2023 | 12/15/2022 | 11/02/2022 | 10/27/2022 | 11/02/2022 | 11/02/2022 |
| GPU | N/A | N/A | 1x Intel¬Æ Arc A770‚Ñ¢ <br>16GB, 512 EU | 1x Intel¬Æ Iris¬Æ <br>Xe Graphics | 1x Intel¬Æ Data Center <br>GPU Flex 170 | 1x Intel¬Æ Arc A770‚Ñ¢ <br>16GB, 512 EU | 1x Intel¬Æ Iris¬Æ <br>Xe Graphics |
| Workload: <br>Codec, <br>resolution, <br>frame rate<br> Model, size (HxW), BS | Yolov8m Model<br>‚Äì input size [640, 640], batch 1<br> FP16 \| int8 | Yolov8m Model<br>‚Äì input size [640, 640], batch 1<br> FP16 \| int8 | Yolov8m Model<br>‚Äì input size [640, 640], batch 1<br> FP16 \| int8 | Yolov8m Model<br>‚Äì input size [640, 640], batch 1<br> FP16 \| int8 | Yolov8m Model<br>‚Äì input size [640, 640], batch 1<br> FP16 \| int8 |  Yolov8m Model<br>‚Äì input size [640, 640], batch 1<br> FP16 \| int8 | Yolov8m Model<br>‚Äì input size [640, 640], batch 1<br> FP16 \| int8 |
| TDP | 350W | 15W | 45W | 235W | 45W | 45W |
| Benchmark Date | May 31, 2023 | May 29, 2023 | June 15, 2023 | May 29, 2023 | June 15, 2023 | May 29, 2023 
| Benchmarked by | Intel Corporation | Intel Corporation | Intel Corporation | Intel Corporation | Intel Corporation | Intel Corporation |

# Additional Resources
- Learn more about [OpenVINO](https://www.intel.com/content/www/us/en/developer/tools/openvino-toolkit/overview.html)
- Explore [OpenVINO‚Äôs documentation](https://docs.openvino.ai/2023.0/home.html)

<p align="right"><a href="#top">Back to top ‚¨ÜÔ∏è</a></p>

[//]: # (telemetry pixel)
<img referrerpolicy="no-referrer-when-downgrade" src="https://static.scarf.sh/a.png?x-pxid=7003a37c-568d-40a5-9718-0d021d8589ca?project=ai_ref_kits/automated_self_checkout?file=README.md" />
