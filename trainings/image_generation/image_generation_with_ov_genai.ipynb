{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d842e782-01a3-4c4b-8bfe-3bbad06ed679",
   "metadata": {},
   "source": [
    "# Image Generation with OpenVINO GenAI\n",
    "\n",
    "## Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4c6948-7de3-418e-9050-aad8e57a66a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openvino-genai optimum-intel nncf huggingface diffusers --extra-index-url https://download.pytorch.org/whl/cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1cd0d6-c952-42b0-bc65-96c5fd13aabd",
   "metadata": {},
   "source": [
    "## Download and convert LCM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7feb7e90-986a-4130-8a28-64b8126379ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from optimum.exporters.openvino.convert import export_tokenizer\n",
    "from optimum.intel import OVPipelineForText2Image\n",
    "\n",
    "lcm_output_dir = \"dreamshaper-v7-lcm\"\n",
    "\n",
    "pipeline = OVPipelineForText2Image.from_pretrained(\"SimianLuo/LCM_Dreamshaper_v7\", export=True)\n",
    "pipeline.save_pretrained(lcm_output_dir)\n",
    "export_tokenizer(pipeline.tokenizer, lcm_output_dir + \"/tokenizer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57dc5b2-3aa9-401d-80cc-d5eca0044682",
   "metadata": {},
   "source": [
    "## Query devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34cfa2a-c5ea-4605-aee6-def1e84a6976",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openvino as ov\n",
    "\n",
    "core = ov.Core()\n",
    "available_devices = core.available_devices\n",
    "\n",
    "print(available_devices)\n",
    "print([core.get_property(device, \"FULL_DEVICE_NAME\") for device in available_devices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47dd273-0519-4e26-bd0d-ec1c64385bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "\n",
    "# Select the model type\n",
    "device_dropdown = widgets.Dropdown(\n",
    "    options=available_devices,\n",
    "    value=\"CPU\",\n",
    "    description=\"Inference device:\"\n",
    ")\n",
    "device_dropdown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5515e34-6469-473a-917d-e94a38cfc1b1",
   "metadata": {},
   "source": [
    "## Run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6beaa8e7-83ce-41c3-94cd-007de12c46ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openvino_genai as ov_genai\n",
    "\n",
    "lcm_pipe = ov_genai.Text2ImagePipeline(lcm_output_dir, device_dropdown.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672d43bb-2646-47c4-a227-e9d44c9a812c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "prompt = \"Cartoon-style adventurer child with a backpack and a treasure map\"\n",
    "\n",
    "steps = 8\n",
    "seed = np.random.randint(2**32)\n",
    "image_tensor = lcm_pipe.generate(prompt, rng_seed=seed, width=512, height=512, num_inference_steps=steps, num_images_per_prompt=1)\n",
    "\n",
    "image = Image.fromarray(image_tensor.data[0])\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1822b0af-17ab-4d0e-9d34-6aed472dbe0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Inference time: {lcm_pipe.get_performance_metrics().get_inference_duration():.2f} ms\")\n",
    "print(f\"{steps} steps, one step time: {lcm_pipe.get_performance_metrics().get_iteration_duration().mean:.2f} ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9347ac69-22c3-4934-ac8c-934d9e60e634",
   "metadata": {},
   "source": [
    "## Download preconverted and preoptimized Flux model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229e9dd8-de54-47e5-9672-606ce355c0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "flux_output_dir = \"flux.1-schnell\"\n",
    "snapshot_download(\"OpenVINO/FLUX.1-schnell-int4-ov\", local_dir=flux_output_dir, resume_download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49346462-f4b7-4faf-8c93-4f5259ecd829",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openvino_genai as ov_genai\n",
    "\n",
    "flux_pipe = ov_genai.Text2ImagePipeline(flux_output_dir, device_dropdown.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423da54c-55f6-40bf-87bc-66b70a6c1ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "prompt = \"Cartoon-style adventurer child with a backpack and a treasure map\"\n",
    "\n",
    "steps = 4\n",
    "seed = np.random.randint(2**32)\n",
    "image_tensor = flux_pipe.generate(prompt, rng_seed=seed, width=512, height=512, num_inference_steps=steps, num_images_per_prompt=1)\n",
    "\n",
    "image = Image.fromarray(image_tensor.data[0])\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f828f8a-190f-4003-a1ae-1de313b73335",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Inference time: {flux_pipe.get_performance_metrics().get_inference_duration():.2f} ms\")\n",
    "print(f\"{steps} steps, one step time: {flux_pipe.get_performance_metrics().get_iteration_duration().mean:.2f} ms\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
