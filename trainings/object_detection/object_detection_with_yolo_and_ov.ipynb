{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd4e4837-6f4e-4b14-b403-dc61fb0f2684",
   "metadata": {},
   "source": [
    "# Object detection with YOLO and OpenVINO\n",
    "\n",
    "## Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf2bd9f-ed76-49bd-bb24-5cde4154042f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install requests ultralytics openvino nncf moviepy --extra-index-url https://download.pytorch.org/whl/cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409bd2bb-cdc3-4248-ad9a-d577bbf13172",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4141ebe3-e26f-42ec-8a3d-cb86ddf37ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy import VideoFileClip\n",
    "\n",
    "# Browser support for mp4 is better than avi, hence conversion is often necessary\n",
    "def avi_to_mp4(video_path):\n",
    "    output_path = video_path.replace(\".avi\", \".mp4\")\n",
    "    with VideoFileClip(video_path) as clip:\n",
    "        # These codecs provide good compression and wide compatibility\n",
    "        clip.write_videofile(output_path, codec='libx264', audio_codec='aac')\n",
    "\n",
    "    return output_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f3a70b-6dca-4645-9c8b-04cafa9a908b",
   "metadata": {},
   "source": [
    "## Get video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61adde2d-c6d9-4b48-bc59-985a4e730eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "from IPython.display import Video\n",
    "\n",
    "\n",
    "def download_video(url, filename):\n",
    "    response = requests.get(url, stream=True)\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Open the file in write-binary mode and save the content\n",
    "        with open(filename, 'wb') as file:\n",
    "            for chunk in response.iter_content(chunk_size=1024):\n",
    "                if chunk:\n",
    "                    file.write(chunk)\n",
    "        print(f\"Download complete: {filename}\")\n",
    "    else:\n",
    "        print(\"Failed to retrieve the file. HTTP Status Code:\", response.status_code)\n",
    "\n",
    "# Download the sample video\n",
    "video_file = \"sample_video.mp4\"\n",
    "download_video(\"https://storage.openvinotoolkit.org/repositories/openvino_notebooks/data/data/video/people.mp4\", video_file)\n",
    "\n",
    "Video(video_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0d8e9d-353b-4a61-9fc1-144447f9d987",
   "metadata": {},
   "source": [
    "## Get model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad923ea-894a-4105-b699-2096268b2ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load the model\n",
    "model_name = \"yolo11n\"\n",
    "yolo_model = YOLO(model_name)\n",
    "\n",
    "# Run prediction on the video\n",
    "results = yolo_model(video_file, save=True, verbose=False)\n",
    "\n",
    "# Convert the video and show\n",
    "processed_video = avi_to_mp4(f\"{results[0].save_dir}/{video_file.replace(\".mp4\", \".avi\")}\")\n",
    "Video(processed_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1e752c-d21d-4cfc-a187-06b28b3c78f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics as stat\n",
    "\n",
    "# Calculate mean inference time (skip first inference which is usually longer)\n",
    "avg_inference_time = stat.mean([r.speed[\"inference\"] for r in results[1:]])\n",
    "print(f\"One image inference time in PyTorch: {avg_inference_time:.2f}ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a8fae6-f7d1-4228-93a6-f2d1f6745351",
   "metadata": {},
   "source": [
    "## Use OpenVINO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8b7438-afea-4bf6-aee5-793106fe896e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the model to OV format with fixed input shape (640x640) and FP16 precision\n",
    "ov_model_path = yolo_model.export(format=\"openvino\", dynamic=False, half=True)\n",
    "\n",
    "# Reload the model\n",
    "ov_yolo_model = YOLO(ov_model_path, task=\"detect\")\n",
    "\n",
    "# Run prediction once again on the video\n",
    "ov_results = ov_yolo_model(video_file, save=True, verbose=False, device=\"intel:cpu\")\n",
    "\n",
    "# Convert the video and show\n",
    "processed_video = avi_to_mp4(f\"{ov_results[0].save_dir}/{video_file.replace(\".mp4\", \".avi\")}\")\n",
    "Video(processed_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21589ebd-531c-4240-b932-fe9224eaad3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics as stat\n",
    "\n",
    "# Calculate mean inference time (skip first inference which is usually longer)\n",
    "avg_ov_inference_time = stat.mean([r.speed[\"inference\"] for r in ov_results[1:]])\n",
    "print(f\"One image inference time in OpenVINO on CPU: {avg_ov_inference_time:.2f}ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fa038e-3675-48bc-bf7d-df8b122fe7ec",
   "metadata": {},
   "source": [
    "## Available devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a426cad-4064-4ea9-af33-5c865c3d076c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openvino as ov\n",
    "\n",
    "core = ov.Core()\n",
    "print(core.available_devices)\n",
    "print([core.get_property(device, \"FULL_DEVICE_NAME\") for device in core.available_devices])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb56b043-951e-48ab-84d2-b5db7c530258",
   "metadata": {},
   "source": [
    "## Try other devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e7e04a-af2c-4d73-985b-108163825931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the model\n",
    "ov_yolo_model = YOLO(ov_model_path, task=\"detect\")\n",
    "# Run inference on GPU\n",
    "ov_gpu_results = ov_yolo_model(video_file, save=True, verbose=False, device=\"intel:gpu\")\n",
    "\n",
    "# Calculate mean inference time (skip first inference which is usually longer)\n",
    "avg_ov_gpu_inference_time = stat.mean([r.speed[\"inference\"] for r in ov_gpu_results[1:]])\n",
    "print(f\"One image inference time in OpenVINO on GPU: {avg_ov_gpu_inference_time:.2f}ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e96ff1-5432-4953-94c8-de526409f559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the model\n",
    "ov_yolo_model = YOLO(ov_model_path, task=\"detect\")\n",
    "# Run inference on NPU\n",
    "ov_npu_results = ov_yolo_model(video_file, save=True, verbose=False, device=\"intel:npu\")\n",
    "\n",
    "# Calculate mean inference time (skip first inference which is usually longer)\n",
    "avg_ov_npu_inference_time = stat.mean([r.speed[\"inference\"] for r in ov_npu_results[1:]])\n",
    "print(f\"One image inference time in OpenVINO on NPU: {avg_ov_npu_inference_time:.2f}ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eea5fc5-05e7-418f-874b-2c5a6f34fda2",
   "metadata": {},
   "source": [
    "## Quantize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7e9159-1164-4d56-bded-c7fb29338425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert and quantize the model to OV format with fixed input shape (640x640) and INT8 precision\n",
    "ov_int8_model_path = yolo_model.export(format=\"openvino\", dynamic=False, int8=True, data=\"coco128.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cac48d3-367a-4ddc-aadc-11665826c617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load int8 model\n",
    "ov_int8_yolo_model = YOLO(ov_int8_model_path, task=\"detect\")\n",
    "# Run inference on GPU\n",
    "ov_int8_gpu_results = ov_int8_yolo_model(video_file, save=True, verbose=False, device=\"intel:gpu\")\n",
    "\n",
    "# Calculate mean inference time (skip first inference which is usually longer)\n",
    "avg_ov_int8_gpu_inference_time = stat.mean([r.speed[\"inference\"] for r in ov_int8_gpu_results[1:]])\n",
    "print(f\"One image inference time in OpenVINO on GPU: {avg_ov_int8_gpu_inference_time:.2f}ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf83424-6cdd-46e8-8b1e-8223583ddf18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the video and show\n",
    "processed_video = avi_to_mp4(f\"{ov_int8_gpu_results[0].save_dir}/{video_file.replace(\".mp4\", \".avi\")}\")\n",
    "Video(processed_video)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
