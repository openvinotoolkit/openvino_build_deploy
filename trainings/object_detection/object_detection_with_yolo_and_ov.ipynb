{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd4e4837-6f4e-4b14-b403-dc61fb0f2684",
   "metadata": {},
   "source": [
    "# Object detection with YOLO and OpenVINO\n",
    "\n",
    "## Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf2bd9f-ed76-49bd-bb24-5cde4154042f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install requests ultralytics openvino nncf moviepy --extra-index-url https://download.pytorch.org/whl/cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f3a70b-6dca-4645-9c8b-04cafa9a908b",
   "metadata": {},
   "source": [
    "## Get video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61adde2d-c6d9-4b48-bc59-985a4e730eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download complete: data/sample_video.mp4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video src=\"data/sample_video.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Video\n",
    "from utils import download_video, avi_to_mp4\n",
    "\n",
    "# Download the sample video\n",
    "video_name = \"sample_video.mp4\"\n",
    "video_file = f\"data/{video_name}\"\n",
    "download_video(\"https://storage.openvinotoolkit.org/repositories/openvino_notebooks/data/data/video/people.mp4\", video_file)\n",
    "\n",
    "Video(video_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0d8e9d-353b-4a61-9fc1-144447f9d987",
   "metadata": {},
   "source": [
    "## Get model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fb5d3b0-8015-4f33-ad9e-8686ab89c307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "863b432d3e8f46fc8d003051dc506bfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Model:', options=('yolo11n', 'yolo11s', 'yolo11m', 'yolo11l', 'yolo11x'), value='yolo11n‚Ä¶"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "\n",
    "# Select the model type\n",
    "model_dropdown = widgets.Dropdown(\n",
    "    options=[\"yolo11n\", \"yolo11s\", \"yolo11m\", \"yolo11l\", \"yolo11x\"],\n",
    "    value=\"yolo11n\",\n",
    "    description=\"Model:\"\n",
    ")\n",
    "model_dropdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ad923ea-894a-4105-b699-2096268b2ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load the model\n",
    "model_name = f\"models/{model_dropdown.value}\"\n",
    "yolo_model = YOLO(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d793d00d-9505-48f1-829b-41f7b289feb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ‚ö†Ô∏è \n",
      "inference results will accumulate in RAM unless `stream=True` is passed, causing potential out-of-memory\n",
      "errors for large sources or long-running streams and videos. See https://docs.ultralytics.com/modes/predict/ for help.\n",
      "\n",
      "Example:\n",
      "    results = model(source=..., stream=True)  # generator of Results objects\n",
      "    for r in results:\n",
      "        boxes = r.boxes  # Boxes object for bbox outputs\n",
      "        masks = r.masks  # Masks object for segment masks outputs\n",
      "        probs = r.probs  # Class probabilities for classification outputs\n",
      "\n",
      "Results saved to \u001b[1m/home/adrian/repos/openvino_build_deploy/runs/detect/predict22\u001b[0m\n",
      "MoviePy - Building video /home/adrian/repos/openvino_build_deploy/runs/detect/predict22/sample_video.mp4.\n",
      "MoviePy - Writing video /home/adrian/repos/openvino_build_deploy/runs/detect/predict22/sample_video.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done !\n",
      "MoviePy - video ready /home/adrian/repos/openvino_build_deploy/runs/detect/predict22/sample_video.mp4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video src=\"/home/adrian/repos/openvino_build_deploy/runs/detect/predict22/sample_video.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run prediction on the video\n",
    "results = yolo_model(video_file, save=True, verbose=False)\n",
    "\n",
    "# Convert the video and show\n",
    "processed_video = avi_to_mp4(f\"{results[0].save_dir}/{video_name.replace(\".mp4\", \".avi\")}\")\n",
    "Video(processed_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c1e752c-d21d-4cfc-a187-06b28b3c78f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One image inference time in PyTorch: 32.20ms\n"
     ]
    }
   ],
   "source": [
    "import statistics as stat\n",
    "\n",
    "# Calculate mean inference time (skip first inference which is usually longer)\n",
    "avg_inference_time = stat.mean([r.speed[\"inference\"] for r in results[1:]])\n",
    "print(f\"One image inference time in PyTorch: {avg_inference_time:.2f}ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a8fae6-f7d1-4228-93a6-f2d1f6745351",
   "metadata": {},
   "source": [
    "## Use OpenVINO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c8b7438-afea-4bf6-aee5-793106fe896e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.116 üöÄ Python-3.13.7 torch-2.9.1+cpu CPU (Intel Core(TM) Ultra 7 258V)\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'models/yolo11n.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 84, 8400) (5.4 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mOpenVINO:\u001b[0m starting export with openvino 2025.4.1-20426-82bbf0292c5-releases/2025/4...\n",
      "\u001b[34m\u001b[1mOpenVINO:\u001b[0m export success ‚úÖ 2.0s, saved as 'models/yolo11n_openvino_model/' (5.4 MB)\n",
      "\n",
      "Export complete (2.2s)\n",
      "Results saved to \u001b[1m/home/adrian/repos/openvino_build_deploy/trainings/object_detection/models\u001b[0m\n",
      "Predict:         yolo predict task=detect model=models/yolo11n_openvino_model imgsz=640 half \n",
      "Validate:        yolo val task=detect model=models/yolo11n_openvino_model imgsz=640 data=/usr/src/ultralytics/ultralytics/cfg/datasets/coco.yaml half \n",
      "Visualize:       https://netron.app\n",
      "Loading models/yolo11n_openvino_model for OpenVINO inference...\n",
      "Using OpenVINO LATENCY mode for batch=1 inference...\n",
      "WARNING ‚ö†Ô∏è \n",
      "inference results will accumulate in RAM unless `stream=True` is passed, causing potential out-of-memory\n",
      "errors for large sources or long-running streams and videos. See https://docs.ultralytics.com/modes/predict/ for help.\n",
      "\n",
      "Example:\n",
      "    results = model(source=..., stream=True)  # generator of Results objects\n",
      "    for r in results:\n",
      "        boxes = r.boxes  # Boxes object for bbox outputs\n",
      "        masks = r.masks  # Masks object for segment masks outputs\n",
      "        probs = r.probs  # Class probabilities for classification outputs\n",
      "\n",
      "Results saved to \u001b[1m/home/adrian/repos/openvino_build_deploy/runs/detect/predict18\u001b[0m\n",
      "MoviePy - Building video /home/adrian/repos/openvino_build_deploy/runs/detect/predict18/sample_video.mp4.\n",
      "MoviePy - Writing video /home/adrian/repos/openvino_build_deploy/runs/detect/predict18/sample_video.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done !\n",
      "MoviePy - video ready /home/adrian/repos/openvino_build_deploy/runs/detect/predict18/sample_video.mp4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video src=\"/home/adrian/repos/openvino_build_deploy/runs/detect/predict18/sample_video.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the model to OV format with fixed input shape (640x640) and FP16 precision\n",
    "ov_model_path = yolo_model.export(format=\"openvino\", dynamic=False, half=True)\n",
    "\n",
    "# Reload the model\n",
    "ov_yolo_model = YOLO(ov_model_path, task=\"detect\")\n",
    "\n",
    "# Run prediction once again on the video\n",
    "ov_results = ov_yolo_model(video_file, save=True, verbose=False, device=\"intel:cpu\")\n",
    "\n",
    "# Convert the video and show\n",
    "processed_video = avi_to_mp4(f\"{ov_results[0].save_dir}/{video_name.replace(\".mp4\", \".avi\")}\")\n",
    "Video(processed_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21589ebd-531c-4240-b932-fe9224eaad3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One image inference time in OpenVINO on CPU: 22.28ms\n"
     ]
    }
   ],
   "source": [
    "import statistics as stat\n",
    "\n",
    "# Calculate mean inference time (skip first inference which is usually longer)\n",
    "avg_ov_inference_time = stat.mean([r.speed[\"inference\"] for r in ov_results[1:]])\n",
    "print(f\"One image inference time in OpenVINO on CPU: {avg_ov_inference_time:.2f}ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fa038e-3675-48bc-bf7d-df8b122fe7ec",
   "metadata": {},
   "source": [
    "## Available devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a426cad-4064-4ea9-af33-5c865c3d076c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CPU', 'GPU', 'NPU']\n",
      "['Intel(R) Core(TM) Ultra 7 258V', 'Intel(R) Arc(TM) Graphics (iGPU)', 'Intel(R) AI Boost']\n"
     ]
    }
   ],
   "source": [
    "import openvino as ov\n",
    "\n",
    "core = ov.Core()\n",
    "available_devices = core.available_devices\n",
    "\n",
    "print(available_devices)\n",
    "print([core.get_property(device, \"FULL_DEVICE_NAME\") for device in available_devices])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb56b043-951e-48ab-84d2-b5db7c530258",
   "metadata": {},
   "source": [
    "## Try other devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5e7e04a-af2c-4d73-985b-108163825931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading models/yolo11n_openvino_model for OpenVINO inference...\n",
      "Using OpenVINO LATENCY mode for batch=1 inference...\n",
      "WARNING ‚ö†Ô∏è \n",
      "inference results will accumulate in RAM unless `stream=True` is passed, causing potential out-of-memory\n",
      "errors for large sources or long-running streams and videos. See https://docs.ultralytics.com/modes/predict/ for help.\n",
      "\n",
      "Example:\n",
      "    results = model(source=..., stream=True)  # generator of Results objects\n",
      "    for r in results:\n",
      "        boxes = r.boxes  # Boxes object for bbox outputs\n",
      "        masks = r.masks  # Masks object for segment masks outputs\n",
      "        probs = r.probs  # Class probabilities for classification outputs\n",
      "\n",
      "Results saved to \u001b[1m/home/adrian/repos/openvino_build_deploy/runs/detect/predict19\u001b[0m\n",
      "One image inference time in OpenVINO on GPU: 12.42ms\n"
     ]
    }
   ],
   "source": [
    "if \"GPU\" in available_devices:\n",
    "    # Reload the model\n",
    "    ov_yolo_model = YOLO(ov_model_path, task=\"detect\")\n",
    "    # Run inference on GPU\n",
    "    ov_gpu_results = ov_yolo_model(video_file, save=True, verbose=False, device=\"intel:gpu\")\n",
    "    \n",
    "    # Calculate mean inference time (skip first inference which is usually longer)\n",
    "    avg_ov_gpu_inference_time = stat.mean([r.speed[\"inference\"] for r in ov_gpu_results[1:]])\n",
    "    print(f\"One image inference time in OpenVINO on GPU: {avg_ov_gpu_inference_time:.2f}ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7e96ff1-5432-4953-94c8-de526409f559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading models/yolo11n_openvino_model for OpenVINO inference...\n",
      "Using OpenVINO LATENCY mode for batch=1 inference...\n",
      "WARNING ‚ö†Ô∏è \n",
      "inference results will accumulate in RAM unless `stream=True` is passed, causing potential out-of-memory\n",
      "errors for large sources or long-running streams and videos. See https://docs.ultralytics.com/modes/predict/ for help.\n",
      "\n",
      "Example:\n",
      "    results = model(source=..., stream=True)  # generator of Results objects\n",
      "    for r in results:\n",
      "        boxes = r.boxes  # Boxes object for bbox outputs\n",
      "        masks = r.masks  # Masks object for segment masks outputs\n",
      "        probs = r.probs  # Class probabilities for classification outputs\n",
      "\n",
      "Results saved to \u001b[1m/home/adrian/repos/openvino_build_deploy/runs/detect/predict20\u001b[0m\n",
      "One image inference time in OpenVINO on NPU: 6.21ms\n"
     ]
    }
   ],
   "source": [
    "if \"NPU\" in available_devices:\n",
    "    # Reload the model\n",
    "    ov_yolo_model = YOLO(ov_model_path, task=\"detect\")\n",
    "    # Run inference on NPU\n",
    "    ov_npu_results = ov_yolo_model(video_file, save=True, verbose=False, device=\"intel:npu\")\n",
    "    \n",
    "    # Calculate mean inference time (skip first inference which is usually longer)\n",
    "    avg_ov_npu_inference_time = stat.mean([r.speed[\"inference\"] for r in ov_npu_results[1:]])\n",
    "    print(f\"One image inference time in OpenVINO on NPU: {avg_ov_npu_inference_time:.2f}ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eea5fc5-05e7-418f-874b-2c5a6f34fda2",
   "metadata": {},
   "source": [
    "## Quantize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d7e9159-1164-4d56-bded-c7fb29338425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.116 üöÄ Python-3.13.7 torch-2.9.1+cpu CPU (Intel Core(TM) Ultra 7 258V)\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'models/yolo11n.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 84, 8400) (5.4 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mOpenVINO:\u001b[0m starting export with openvino 2025.4.1-20426-82bbf0292c5-releases/2025/4...\n",
      "\u001b[34m\u001b[1mOpenVINO:\u001b[0m collecting INT8 calibration images from 'data=coco128.yaml'\n",
      "Fast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 280.8¬±101.5 MB/s, size: 49.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning /home/adrian/repos/datasets/coco128/labels/train2017.cache... 126 image"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ‚ö†Ô∏è \u001b[34m\u001b[1mOpenVINO:\u001b[0m >300 images recommended for INT8 calibration, found 128 images.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:nncf:15 ignored nodes were found by patterns in the NNCFGraph\n",
      "INFO:nncf:1 ignored nodes were found by types in the NNCFGraph\n",
      "INFO:nncf:Not adding activation input quantizer for operation: 168 __module.model.23.dfl/aten::view/Reshape\n",
      "INFO:nncf:Not adding activation input quantizer for operation: 169 __module.model.23/aten::sigmoid/Sigmoid\n",
      "INFO:nncf:Not adding activation input quantizer for operation: 180 __module.model.23.dfl/aten::transpose/Transpose\n",
      "INFO:nncf:Not adding activation input quantizer for operation: 191 __module.model.23.dfl/aten::softmax/Softmax\n",
      "INFO:nncf:Not adding activation input quantizer for operation: 200 __module.model.23.dfl.conv/aten::_convolution/Convolution\n",
      "INFO:nncf:Not adding activation input quantizer for operation: 208 __module.model.23.dfl/aten::view/Reshape_1\n",
      "INFO:nncf:Not adding activation input quantizer for operation: 226 __module.model.23/aten::sub/Subtract\n",
      "INFO:nncf:Not adding activation input quantizer for operation: 227 __module.model.23/aten::add/Add\n",
      "INFO:nncf:Not adding activation input quantizer for operation: 236 __module.model.23/aten::add/Add_1\n",
      "246 __module.model.23/aten::div/Divide\n",
      "\n",
      "INFO:nncf:Not adding activation input quantizer for operation: 237 __module.model.23/aten::sub/Subtract_1\n",
      "INFO:nncf:Not adding activation input quantizer for operation: 256 __module.model.23/aten::mul/Multiply\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51b61527814444bdb0e74401bac6f27a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:nncf:Dataset contains only 128 samples, smaller than the requested subset size 300.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5725a5ced0fa4fdf94783c4d8048d20e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mOpenVINO:\u001b[0m export success ‚úÖ 13.1s, saved as 'models/yolo11n_int8_openvino_model/' (3.3 MB)\n",
      "\n",
      "Export complete (13.2s)\n",
      "Results saved to \u001b[1m/home/adrian/repos/openvino_build_deploy/trainings/object_detection/models\u001b[0m\n",
      "Predict:         yolo predict task=detect model=models/yolo11n_int8_openvino_model imgsz=640 int8 \n",
      "Validate:        yolo val task=detect model=models/yolo11n_int8_openvino_model imgsz=640 data=/usr/src/ultralytics/ultralytics/cfg/datasets/coco.yaml int8 \n",
      "Visualize:       https://netron.app\n"
     ]
    }
   ],
   "source": [
    "# Convert and quantize the model to OV format with fixed input shape (640x640) and INT8 precision\n",
    "ov_int8_model_path = yolo_model.export(format=\"openvino\", dynamic=False, int8=True, data=\"coco128.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70fe0fa3-fb7d-4798-8ee1-85c940a65b8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc19fcfca2334b14abfefb84c6fa2c72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Device:', options=('CPU', 'GPU', 'NPU'), value='CPU')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "\n",
    "# Select the model type\n",
    "device_dropdown = widgets.Dropdown(\n",
    "    options=available_devices,\n",
    "    value=\"CPU\",\n",
    "    description=\"Device:\"\n",
    ")\n",
    "device_dropdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8cac48d3-367a-4ddc-aadc-11665826c617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading models/yolo11n_int8_openvino_model for OpenVINO inference...\n",
      "Using OpenVINO LATENCY mode for batch=1 inference...\n",
      "WARNING ‚ö†Ô∏è \n",
      "inference results will accumulate in RAM unless `stream=True` is passed, causing potential out-of-memory\n",
      "errors for large sources or long-running streams and videos. See https://docs.ultralytics.com/modes/predict/ for help.\n",
      "\n",
      "Example:\n",
      "    results = model(source=..., stream=True)  # generator of Results objects\n",
      "    for r in results:\n",
      "        boxes = r.boxes  # Boxes object for bbox outputs\n",
      "        masks = r.masks  # Masks object for segment masks outputs\n",
      "        probs = r.probs  # Class probabilities for classification outputs\n",
      "\n",
      "Results saved to \u001b[1m/home/adrian/repos/openvino_build_deploy/runs/detect/predict21\u001b[0m\n",
      "One image inference time in OpenVINO on CPU: 12.31ms\n"
     ]
    }
   ],
   "source": [
    "# Load int8 model\n",
    "ov_int8_yolo_model = YOLO(ov_int8_model_path, task=\"detect\")\n",
    "# Run inference on the selected device\n",
    "ov_int8_results = ov_int8_yolo_model(video_file, save=True, verbose=False, device=f\"intel:{device_dropdown.value}\")\n",
    "\n",
    "# Calculate mean inference time (skip first inference which is usually longer)\n",
    "avg_ov_int8_inference_time = stat.mean([r.speed[\"inference\"] for r in ov_int8_results[1:]])\n",
    "print(f\"One image inference time in OpenVINO on {device_dropdown.value}: {avg_ov_int8_inference_time:.2f}ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3bf83424-6cdd-46e8-8b1e-8223583ddf18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Building video /home/adrian/repos/openvino_build_deploy/runs/detect/predict21/sample_video.mp4.\n",
      "MoviePy - Writing video /home/adrian/repos/openvino_build_deploy/runs/detect/predict21/sample_video.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done !\n",
      "MoviePy - video ready /home/adrian/repos/openvino_build_deploy/runs/detect/predict21/sample_video.mp4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video src=\"/home/adrian/repos/openvino_build_deploy/runs/detect/predict21/sample_video.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the video and show\n",
    "processed_video = avi_to_mp4(f\"{ov_int8_results[0].save_dir}/{video_name.replace(\".mp4\", \".avi\")}\")\n",
    "Video(processed_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583fc0fe-4f0b-4ede-a9d7-f947dc9eede6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
